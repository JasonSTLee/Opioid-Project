{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## US Census Bureau API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "import requests\n",
    "import os \n",
    "from pprint import pprint\n",
    "import glob\n",
    "\n",
    "pd.set_option('display.float_format', '{:.5f}'.format)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = open('/Users/admin/Desktop/opioid_project/census_api_key.txt').read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the population from every state, every year from 2009 to 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalDF = []\n",
    "# even though the opioid dataset is from 2006 to 2019, the census bureau's variable for population doesn't go back past 2009 so I need to start from that year\n",
    "yearList = pd.Series(range(2009,2020)).to_list()\n",
    "yearList\n",
    "variablesList = 'B01001_001E'\n",
    "\n",
    "for year in yearList:\n",
    "    url = f'https://api.census.gov/data/{year}/acs/acs5?get=NAME,{variablesList}&for=state:*&key={api_key}'\n",
    "    data = requests.get(url)\n",
    "    # the output is a list of lists in which the first lists is the header values / columns, and subsequent values in the list are rows\n",
    "    data = data.json()\n",
    "    \n",
    "    # turning the output into a dataframe\n",
    "    df = pd.DataFrame(data)\n",
    "    # turning the first row into columns\n",
    "    df.columns = df.iloc[0]\n",
    "    # since the first row is now the columns / header, I need rows starting at [1]\n",
    "    df = df[1:]\n",
    "    \n",
    "    df['year'] = year\n",
    "    \n",
    "    totalDF.append(df)\n",
    "\n",
    "\n",
    "df = pd.concat(totalDF, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='state', axis = 1)\n",
    "df = df[df['NAME'] != 'Puerto Rico']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns= \n",
    "                {'B01001_001E': 'population',\n",
    "                 'NAME': 'state'\n",
    "                })\n",
    "df.to_csv('census.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading all the csv's and using certain columns so it'll be smaller when I import to PG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/admin/Desktop/states/arcos-*-statewide-itemized.csv'\n",
    "files = glob.glob(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    df = pd.read_csv(file, usecols= ['TRANSACTION_DATE',\n",
    "                                     'REPORTER_DEA_NO',\n",
    "                                     'REPORTER_BUS_ACT',\n",
    "                                     'REPORTER_NAME',\n",
    "                                     'REPORTER_COUNTY',\n",
    "                                     'REPORTER_STATE',\n",
    "                                     'BUYER_DEA_NO',\n",
    "                                     'BUYER_BUS_ACT',\n",
    "                                     'BUYER_NAME',\n",
    "                                     'BUYER_COUNTY',\n",
    "                                     'BUYER_STATE',\n",
    "                                     'DRUG_NAME',\n",
    "                                     'Combined_Labeler_Name',\n",
    "                                     'Reporter_family',\n",
    "                                     'CALC_BASE_WT_IN_GM',\n",
    "                                     'DOSAGE_UNIT'])\n",
    "    \n",
    "    # using split because all file names share the same pattern, and I can split with the hyphen and get the second value from splitting, which is the state name abbreviation\n",
    "    state_abbreviation = file.split('-')[1]\n",
    "    state_name = f'{state_abbreviation}.csv'\n",
    "    \n",
    "    # I want separate csv's and will be appending in Postgres\n",
    "    df.to_csv(state_name, index= False)\n",
    "    \n",
    "    print(f\"{state_abbreviation} and {state_name} is done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
